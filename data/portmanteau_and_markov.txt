a
portmanteau
ˌpɔːrtmænˈtoʊ
or
portmanteau
word
is
a
linguistic
blend
of
words
in
which
parts
of
multiple
words
or
their
phones
are
combined
into
a
new
word
as
in
smog
coined
by
blending
smoke
and
fog
or
motel
from
motor
and
hotel
in
linguistics
a
portmanteau
is
defined
as
a
single
morph
that
represents
two
or
more
morphemes
the
definition
overlaps
with
the
grammatical
term
contraction
but
contractions
are
formed
from
words
that
would
otherwise
appear
together
in
sequence
such
as
do
and
not
to
make
dont
whereas
a
portmanteau
word
is
formed
by
combining
two
or
more
existing
words
that
all
relate
to
a
singular
concept
a
portmanteau
also
differs
from
a
compound
which
does
not
involve
the
truncation
of
parts
of
the
stems
of
the
blended
words
for
instance
starfish
is
a
compound
not
a
portmanteau
of
star
and
fish
as
it
includes
both
words
in
full
the
word
portmanteau
was
first
used
in
this
sense
by
lewis
carroll
in
the
book
through
the
looking
glass
in
which
humpty
dumpty
explains
to
alice
the
coinage
of
the
unusual
words
in
jabberwocky
where
slithy
means
slimy
and
lithe
and
mimsy
is
miserable
and
flimsy
humpty
dumpty
explains
to
alice
the
practice
of
combining
words
in
various
ways
you
see
its
like
a
portmanteauthere
are
two
meanings
packed
up
into
one
word
in
his
introduction
to
the
hunting
of
the
snark
carroll
uses
portmanteau
when
discussing
lexical
selection
humpty
dumptys
theory
of
two
meanings
packed
into
one
word
like
a
portmanteau
seems
to
me
the
right
explanation
for
all
for
instance
take
the
two
words
fuming
and
furious
make
up
your
mind
that
you
will
say
both
words
but
leave
it
unsettled
which
you
will
say
first
if
you
have
the
rarest
of
gifts
a
perfectly
balanced
mind
you
will
say
frumious
in
then
contemporary
english
a
portmanteau
was
a
suitcase
that
opened
into
two
equal
sections
the
etymology
of
the
word
is
the
french
porte
manteau
from
porter
to
carry
and
manteau
cloak
in
modern
french
a
porte
manteau
is
a
clothes
valet
a
coat
tree
or
similar
article
of
furniture
for
hanging
up
jackets
hats
umbrellas
and
the
like
an
occasional
synonym
for
portmanteau
word
is
frankenword
an
autological
word
exemplifying
the
phenomenon
it
describes
blending
frankenstein
and
word
many
neologisms
are
examples
of
blends
but
many
blends
have
become
part
of
the
lexicon
in
punch
in
the
word
brunch
was
introduced
as
a
portmanteau
word
in
the
newly
independent
african
republic
of
tanganyika
and
zanzibar
chose
the
portmanteau
word
tanzania
as
its
name
similarly
eurasia
is
a
portmanteau
of
europe
and
asia
some
city
names
are
portmanteaus
of
the
border
regions
they
straddle
texarkana
spreads
across
the
texas
arkansas
border
while
calexico
and
mexicali
are
respectively
the
american
and
mexican
sides
of
a
single
conurbation
a
scientific
example
is
a
liger
which
is
a
cross
between
a
male
lion
and
a
female
tiger
many
company
or
brand
names
are
portmanteaus
including
microsoft
a
portmanteau
of
microcomputer
and
software
the
cheese
cambozola
combines
a
similar
rind
to
camembert
with
the
same
mold
used
to
make
gorgonzola
passenger
rail
company
amtrak
a
portmanteau
of
america
and
track
velcro
a
portmanteau
of
the
french
velours
and
crochet
verizon
a
portmanteau
of
veritas
and
horizon
and
comed
a
portmanteau
of
commonwealth
and
edison
jeoportmanteau
is
a
recurring
category
on
the
american
television
quiz
show
jeopardy
the
categorys
name
is
itself
a
portmanteau
of
the
words
jeopardy
and
portmanteau
responses
in
the
category
are
portmanteaus
constructed
by
fitting
two
words
together
portmanteau
words
may
be
produced
by
joining
together
proper
nouns
with
common
nouns
such
as
gerrymandering
which
refers
to
the
scheme
of
massachusetts
governor
elbridge
gerry
for
politically
contrived
redistricting
the
perimeter
of
one
of
the
districts
thereby
created
resembled
a
very
curvy
salamander
in
outline
the
term
gerrymander
has
itself
contributed
to
portmanteau
terms
bjelkemander
and
playmander
oxbridge
is
a
common
portmanteau
for
the
uks
two
oldest
universities
those
of
oxford
and
cambridge
in
britains
planned
exit
from
the
european
union
became
known
as
brexit
a
spork
many
portmanteau
words
receive
some
use
but
do
not
appear
in
all
dictionaries
for
example
a
spork
is
an
eating
utensil
that
is
a
combination
of
a
spoon
and
a
fork
and
a
skort
is
an
item
of
clothing
that
is
part
skirt
part
shorts
on
the
other
hand
turducken
a
dish
made
by
inserting
a
chicken
into
a
duck
and
the
duck
into
a
turkey
was
added
to
the
oxford
english
dictionary
in
similarly
the
word
refudiate
was
first
used
by
sarah
palin
when
she
misspoke
conflating
the
words
refute
and
repudiate
though
initially
a
gaffe
the
word
was
recognized
as
the
new
oxford
american
dictionarys
word
of
the
year
in
the
business
lexicon
is
replete
with
newly
coined
portmanteau
words
like
permalance
advertainment
advertorial
infotainment
and
infomercial
a
company
name
may
also
be
portmanteau
and
kleenex
as
well
as
a
product
name
name
meshing
main
article
name
blending
two
proper
names
can
also
be
used
in
creating
a
portmanteau
word
in
reference
to
the
partnership
between
people
especially
in
cases
where
both
persons
are
well
known
or
sometimes
to
produce
epithets
such
as
billary
in
this
example
of
recent
american
political
history
the
purpose
for
blending
is
not
so
much
to
combine
the
meanings
of
the
source
words
but
to
suggest
a
resemblance
of
one
named
person
to
the
other
the
effect
is
often
derogatory
as
linguist
benjamin
zimmer
states
by
contrast
the
public
including
the
media
use
portmanteaus
to
refer
to
their
favorite
pairings
as
a
way
to
giv
people
an
essence
of
who
they
are
within
the
same
name
this
is
particularly
seen
in
cases
of
fictional
and
real
life
supercouples
an
early
known
example
bennifer
referred
to
film
stars
ben
affleck
and
jennifer
lopez
other
examples
include
brangelina
and
tomkat
desilu
productions
was
a
los
angeles
california
based
company
jointly
owned
by
couple
and
actors
desi
arnaz
and
lucille
ball
miramax
is
the
combination
of
the
first
names
of
the
parents
of
the
weinstein
brothers
on
wednesday
june
the
new
york
times
crossword
included
the
quip
how
i
wish
natalie
portman
dated
jacques
cousteau
so
i
could
call
them
portmanteau
holidays
are
another
example
as
in
thanksgivukkah
a
portmanteau
neologism
given
to
the
convergence
of
the
american
holiday
of
thanksgiving
and
the
first
day
of
the
jewish
holiday
of
hanukkah
on
thursday
november
in
the
disney
film
big
hero
the
film
is
situated
in
a
fictitious
city
called
san
fransokyo
which
is
a
portmanteau
of
two
real
locations
san
francisco
and
tokyo
a
markov
chain
is
a
stochastic
model
describing
a
sequence
of
possible
events
in
which
the
probability
of
each
event
depends
only
on
the
state
attained
in
the
previous
event
in
probability
theory
and
related
fields
a
markov
process
named
after
the
russian
mathematician
andrey
markov
is
a
stochastic
process
that
satisfies
the
markov
property
roughly
speaking
a
process
satisfies
the
markov
property
if
one
can
make
predictions
for
the
future
of
the
process
based
solely
on
its
present
state
just
as
well
as
one
could
knowing
the
processs
full
history
hence
independently
from
such
history
ie
conditional
on
the
present
state
of
the
system
its
future
and
past
states
are
independent
a
markov
chain
is
a
type
of
markov
process
that
has
either
a
discrete
state
space
or
a
discrete
index
set
but
the
precise
definition
of
a
markov
chain
varies
for
example
it
is
common
to
define
a
markov
chain
as
a
markov
process
in
either
discrete
or
continuous
time
with
a
countable
state
space
but
it
is
also
common
to
define
a
markov
chain
as
having
discrete
time
in
either
countable
or
continuous
state
space
markov
studied
markov
processes
in
the
early
th
century
publishing
his
first
paper
on
the
topic
in
random
walks
based
on
integers
and
the
gamblers
ruin
problem
are
examples
of
markov
processes
some
variations
of
these
processes
were
studied
hundreds
of
years
earlier
in
the
context
of
independent
variables
two
important
examples
of
markov
processes
are
the
wiener
process
also
known
as
the
brownian
motion
process
and
the
poisson
process
which
are
considered
the
most
important
and
central
stochastic
processes
in
the
theory
of
stochastic
processes
and
were
discovered
repeatedly
and
independently
both
before
and
after
in
various
settings
these
two
processes
are
markov
processes
in
continuous
time
while
random
walks
on
the
integers
and
the
gamblers
ruin
problem
are
examples
of
markov
processes
in
discrete
time
markov
chains
have
many
applications
as
statistical
models
of
real
world
processes
such
as
studying
cruise
control
systems
in
motor
vehicles
queues
or
lines
of
customers
arriving
at
an
airport
exchange
rates
of
currencies
storage
systems
such
as
dams
and
population
growths
of
certain
animal
species
the
algorithm
known
as
pagerank
which
was
originally
proposed
for
the
internet
search
engine
google
is
based
on
a
markov
process
markov
processes
are
the
basis
for
general
stochastic
simulation
methods
known
as
markov
chain
monte
carlo
which
are
used
for
simulating
sampling
from
complex
probability
distributions
and
have
found
extensive
application
in
bayesian
statistics
the
adjective
markovian
is
used
to
describe
something
that
is
related
to
a
markov
process
markov
chains
are
used
throughout
information
processing
claude
shannons
famous
paper
a
mathematical
theory
of
communication
which
in
a
single
step
created
the
field
of
information
theory
opens
by
introducing
the
concept
of
entropy
through
markov
modeling
of
the
english
language
such
idealized
models
can
capture
many
of
the
statistical
regularities
of
systems
even
without
describing
the
full
structure
of
the
system
perfectly
such
signal
models
can
make
possible
very
effective
data
compression
through
entropy
encoding
techniques
such
as
arithmetic
coding
they
also
allow
effective
state
estimation
and
pattern
recognition
markov
chains
also
play
an
important
role
in
reinforcement
learning
markov
chains
are
also
the
basis
for
hidden
markov
models
which
are
an
important
tool
in
such
diverse
fields
as
telephone
networks
speech
recognition
and
bioinformatics
the
lzma
lossless
data
compression
algorithm
combines
markov
chains
with
lempel
ziv
compression
to
achieve
very
high
compression
ratios
markov
chains
can
be
used
to
model
many
games
of
chance
the
childrens
games
snakes
and
ladders
and
hi
ho
cherry
o
for
example
are
represented
exactly
by
markov
chains
at
each
turn
the
player
starts
in
a
given
state
and
from
there
has
fixed
odds
of
moving
to
certain
other
states
markov
processes
can
also
be
used
to
generate
superficially
real
looking
text
given
a
sample
document
markov
processes
are
used
in
a
variety
of
recreational
parody
generator
software
a
second
order
markov
chain
can
be
introduced
by
considering
the
current
state
and
also
the
previous
state
as
indicated
in
the
second
table
higher
nth
order
chains
tend
to
group
particular
notes
together
while
breaking
off
into
other
patterns
and
sequences
occasionally
these
higher
order
chains
tend
to
generate
results
with
a
sense
of
phrasal
structure
rather
than
the
aimless
wandering
produced
by
a
first
order
system
markov
chains
can
be
used
structurally
as
in
xenakiss
analogique
a
and
b
markov
chains
are
also
used
in
systems
which
use
a
markov
model
to
react
interactively
to
music
input
usually
musical
systems
need
to
enforce
specific
control
constraints
on
the
finite
length
sequences
they
generate
but
control
constraints
are
not
compatible
with
markov
models
since
they
induce
long
range
dependencies
that
violate
the
markov
hypothesis
of
limited
memory
in
order
to
overcome
this
limitation
a
new
approach
has
been
proposed
markov
chains
are
employed
in
algorithmic
music
composition
particularly
in
software
such
as
csound
max
and
supercollider
in
a
first
order
chain
the
states
of
the
system
become
note
or
pitch
values
and
a
probability
vector
for
each
note
is
constructed
completing
a
transition
probability
matrix
an
algorithm
is
constructed
to
produce
output
note
values
based
on
the
transition
matrix
weightings
which
could
be
midi
note
values
frequency
or
any
other
desirable
metric
note
that
there
is
no
definitive
agreement
in
the
literature
on
the
use
of
some
of
the
terms
that
signify
special
cases
of
markov
processes
usually
the
term
markov
chain
is
reserved
for
a
process
with
a
discrete
set
of
times
ie
a
discrete
time
markov
chain
but
a
few
authors
use
the
term
markov
process
to
refer
to
a
continuous
time
markov
chain
without
explicit
mention
in
addition
there
are
other
extensions
of
markov
processes
that
are
referred
to
as
such
but
do
not
necessarily
fall
within
any
of
these
four
categories
moreover
the
time
index
need
not
necessarily
be
real
valued
like
with
the
state
space
there
are
conceivable
processes
that
move
through
index
sets
with
other
mathematical
constructs
notice
that
the
general
state
space
continuous
time
markov
chain
is
general
to
such
a
degree
that
it
has
no
designated
term
while
the
time
parameter
is
usually
discrete
the
state
space
of
a
markov
chain
does
not
have
any
generally
agreed
on
restrictions
the
term
may
refer
to
a
process
on
an
arbitrary
state
space
however
many
applications
of
markov
chains
employ
finite
or
countably
infinite
state
spaces
which
have
a
more
straightforward
statistical
analysis
besides
time
index
and
state
space
parameters
there
are
many
other
variations
extensions
and
generalizations
for
simplicity
most
of
this
article
concentrates
on
the
discrete
time
discrete
state
space
case
unless
mentioned
otherwise
the
changes
of
state
of
the
system
are
called
transitions
the
probabilities
associated
with
various
state
changes
are
called
transition
probabilities
the
process
is
characterized
by
a
state
space
a
transition
matrix
describing
the
probabilities
of
particular
transitions
and
an
initial
state
across
the
state
space
by
convention
we
assume
all
possible
states
and
transitions
have
been
included
in
the
definition
of
the
process
so
there
is
always
a
next
state
and
the
process
does
not
terminate
a
discrete
time
random
process
involves
a
system
which
is
in
a
certain
state
at
each
step
with
the
state
changing
randomly
between
steps
the
steps
are
often
thought
of
as
moments
in
time
but
they
can
equally
well
refer
to
physical
distance
or
any
other
discrete
measurement
formally
the
steps
are
the
integers
or
natural
numbers
and
the
random
process
is
a
mapping
of
these
to
states
the
markov
property
states
that
the
conditional
probability
distribution
for
the
system
at
the
next
step
depends
only
on
the
current
state
of
the
system
and
not
additionally
on
the
state
of
the
system
at
previous
steps
since
the
system
changes
randomly
it
is
generally
impossible
to
predict
with
certainty
the
state
of
a
markov
chain
at
a
given
point
in
the
future
however
the
statistical
properties
of
the
systems
future
can
be
predicted
in
many
applications
it
is
these
statistical
properties
that
are
important
a
famous
markov
chain
is
the
so
called
drunkards
walk
a
random
walk
on
the
number
line
where
at
each
step
the
position
may
change
by
or
with
equal
probability
from
any
position
there
are
two
possible
transitions
to
the
next
or
previous
integer
the
transition
probabilities
depend
only
on
the
current
position
not
on
the
manner
in
which
the
position
was
reached
for
example
the
transition
probabilities
from
to
and
to
are
both
and
all
other
transition
probabilities
from
are
these
probabilities
are
independent
of
whether
the
system
was
previously
in
or
another
example
is
the
dietary
habits
of
a
creature
who
eats
only
grapes
cheese
or
lettuce
and
whose
dietary
habits
conform
to
the
following
rules
it
eats
exactly
once
a
day
if
it
ate
cheese
today
tomorrow
it
will
eat
lettuce
or
grapes
with
equal
probability
if
it
ate
grapes
today
tomorrow
it
will
eat
grapes
with
probability
cheese
with
probability
and
lettuce
with
probability
if
it
ate
lettuce
today
tomorrow
it
will
eat
grapes
with
probability
or
cheese
with
probability
it
will
not
eat
lettuce
again
tomorrow
this
creatures
eating
habits
can
be
modeled
with
a
markov
chain
since
its
choice
tomorrow
depends
solely
on
what
it
ate
today
not
what
it
ate
yesterday
or
any
other
time
in
the
past
one
statistical
property
that
could
be
calculated
is
the
expected
percentage
over
a
long
period
of
the
days
on
which
the
creature
will
eat
grapes
a
series
of
independent
events
satisfies
the
formal
definition
of
a
markov
chain
however
the
theory
is
usually
applied
only
when
the
probability
distribution
of
the
next
step
depends
non
trivially
on
the
current
state
a
markov
chain
is
a
stochastic
process
with
the
markov
property
the
term
markov
chain
refers
to
the
sequence
of
random
variables
such
a
process
moves
through
with
the
markov
property
defining
serial
dependence
only
between
adjacent
periods
it
can
thus
be
used
for
describing
systems
that
follow
a
chain
of
linked
events
where
what
happens
next
depends
only
on
the
current
state
of
the
system
the
systems
state
space
and
time
parameter
index
need
to
be
specified
the
following
table
gives
an
overview
of
the
different
instances
of
markov
processes
for
different
levels
of
state
space
generality
and
for
discrete
time
v
continuous
time